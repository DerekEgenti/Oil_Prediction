# -*- coding: utf-8 -*-
"""RF_Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Jw8f7VcJk5yTFQVdQvjX2IOKOnDk16vW
"""

#install the seaborn library for pairplot.
!pip install -q seaborn

#install other libraries
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns

# Make NumPy printouts easier to read.
np.set_printoptions(precision=3, suppress=True)

"""Import dataset"""

df = pd.read_csv('https://query.data.world/s/n6l4y5oiu6ahbbchatnv22tqen6zeb?dws=00000')

df.head()

df.shape

df.dtypes

"""Rename some of the columns because the space will not allow for calling of the columns"""

list(df.columns)

def remove_spaces_and_commas(columns):
    return [column.replace(" ", "").replace(",", "") for column in columns]

def clean_column_names(df):
    cleaned_columns = remove_spaces_and_commas(df.columns)
    df.rename(columns=dict(zip(df.columns, cleaned_columns)), inplace=True)


clean_column_names(df)

print("\nDataFrame with Cleaned Column Names:")
df.head()

"""Now we do some data analysis. First, we chack for missing values."""

df.isna().sum()

"""The aim of thiss project is to model production variations in the wells documented in this dataset, so therefore, due to the large number of missing values in the purchaser codes column, i have decide to drop it."""

df.drop('PurchaserCodes', axis=1, inplace=True)
df.head()

"""Then i simply drop the missing rows from the other coulumns."""

df.dropna(inplace=True)

df.isna().sum()

df.count()

"""Now we do some visualizations to observe trends"""

unique_entries1 = df['County'].unique()
unique_entries1

unique_entries2 = df['Town'].unique()
unique_entries2

total_entries2 = len(unique_entries2)
total_entries2

unique_entries3 = df['ProducingFormation'].unique()
unique_entries3

total_entries3 = len(unique_entries3)
total_entries3

unique_entries10 = df['Self-useWell'].unique()
unique_entries10

unique_entries4 = df['Field'].unique()
unique_entries4

total_entries4 = len(unique_entries4)
total_entries4

"""**GRAPHS**"""

df = df.sort_values(by='ProductionYear')

#Plotting bar chart
plt.figure(figsize=(18, 9))
plt.bar(df['ProductionYear'], df['OilProducedbbl'], color='r', label='Oil Produced')
plt.xlabel('Year')
plt.ylabel('Oil Produced (bbl)')
plt.title('Oil Production Over the Years')
plt.legend()
plt.grid(axis='y')
plt.show()

max_valueOil = df['OilProducedbbl'].max()
max_valueOil

df = df.sort_values(by='ProductionYear')

#Plotting bar chart
plt.figure(figsize=(18, 9))
plt.bar(df['ProductionYear'], df['GasProducedMcf'], color='b', label='Gas Produced')
plt.xlabel('Year')
plt.ylabel('Gas Produced (Mcf)')
plt.title('Gas Production Over the Years')
plt.legend()
plt.grid(axis='y')
plt.show()

max_valueGas = df['GasProducedMcf'].max()
max_valueGas

df = df.sort_values(by='ProductionYear')

#Plotting bar chart
plt.figure(figsize=(18, 9))
plt.bar(df['ProductionYear'], df['Waterproducedbbl'], color='g', label='Water Produced')
plt.xlabel('Year')
plt.ylabel('Water Produced (bbl)')
plt.title('Water Production Over the Years')
plt.legend()
plt.grid(axis='y')
plt.show()

max_valueWater = df['Waterproducedbbl'].max()
max_valueWater

df = df.sort_values(by='ProductionYear')

#Plotting bar chart
plt.figure(figsize=(18, 9))
plt.bar(df['County'], df['ActiveOilWells'], color='g', label='Active Oil wells')
plt.xlabel('County')
plt.ylabel('Active Oil wells per County')
plt.title('County With The Most Active Oil Wells')
plt.xticks(rotation=45, ha='right')
plt.legend()
plt.grid(axis='y')
plt.show()

df = df.sort_values(by='ProductionYear')

#Plotting bar chart
plt.figure(figsize=(18, 9))
plt.bar(df['County'], df['InactiveOilWells'], color='g', label='Inactive Oil wells')
plt.xlabel('County')
plt.ylabel('Inactive Oil wells per County')
plt.title('County With The Most Inactive Oil Wells')
plt.xticks(rotation=45, ha='right')
plt.legend()
plt.grid(axis='y')
plt.show()

"""#####Maybe do more visualizations for data analysis later"""

df = df.sort_values(by='ProductionYear')

#Plotting bar chart
plt.figure(figsize=(18, 9))
plt.bar(df['County'], df['ActiveGasWells'], color='g', label='Active Gas wells')
plt.xlabel('County')
plt.ylabel('Active Gas wells per County')
plt.title('County With The Most Active Gas Wells')
plt.xticks(rotation=45, ha='right')
plt.legend()
plt.grid(axis='y')
plt.show()

fig, ax = plt.subplots(figsize=(20, 12))

bar1 = ax.bar(df['ProductionYear'], df['Waterproducedbbl'], label='Water')

bar2 = ax.bar(df['ProductionYear'], df['GasProducedMcf'], label='Gas', bottom=df['Waterproducedbbl'])

bar3 = ax.bar(df['ProductionYear'], df['OilProducedbbl'], label='Oil', bottom=df['Waterproducedbbl'])

ax.set_ylabel('Values')
ax.set_title('Stacked Bar Chart')
ax.legend()

plt.show()

df.columns.tolist()

"""Important Columns

1. Active Oil Well
2. Injection Wells
3. Oil Produced bbl


"""

list(df.columns)

corr = df.corr()

fig, ax = plt.subplots(figsize=(10, 8))

sns.heatmap(corr, cmap='RdBu', vmin=-1, vmax=1, annot=True, ax=ax)

plt.show()

df.corr()

"""Create a model to predict Oil Produced"""

df.head()

df.drop(['ProductionYear','ProductionDateEntered','Operator','County','Town','Field','ProducingFormation','InactiveOilWells','ActiveGasWells','InactiveGasWells','DisposalWells','Self-useWell','GasProducedMcf','Waterproducedbbl','TaxableGasMcf',
 'Location'], axis=1, inplace=True)

df.describe()

df.head()

count_zeros = (df['ActiveOilWells'] == 0).sum()

print(f"The number of rows in 'Column1' with value zero is: {count_zeros}")

count_zeros1 = (df['InjectionWells'] == 0).sum()

print(f"The number of rows in 'Column1' with value zero is: {count_zeros1}")

count_zeros2 = (df['OilProducedbbl'] == 0).sum()

print(f"The number of rows in 'Column1' with value zero is: {count_zeros2}")

df = df[(df != 0).all(axis=1)]

df

df.info()

df

"""We attempt fitting multiple models to see the best one, and subsequently go with that one."""

from sklearn.model_selection import KFold
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_squared_error, r2_score

# Example data
X = df.drop(['OilProducedbbl'], axis=1)
y = df['OilProducedbbl']


# Number of folds for cross-validation
num_folds = 5

# Initialize KFold cross-validator
kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)

# Initialize models
model1 = LinearRegression()
model2 = XGBRegressor()
model3 = RandomForestRegressor()

# Lists to store performance metrics across folds
mse_scores_model1 = []
mse_scores_model2 = []
mse_scores_model3 = []
r2_scores_model1 = []
r2_scores_model2 = []
r2_scores_model3 = []

# Perform k-fold cross-validation
for train_index, val_index in kf.split(X):
    X_train, X_val = X.iloc[train_index], X.iloc[val_index]
    y_train, y_val = y.iloc[train_index], y.iloc[val_index]

    # Train the models
    model1.fit(X_train, y_train)
    model2.fit(X_train, y_train)
    model3.fit(X_train, y_train)

    # Make predictions on the validation set
    y_pred1 = model1.predict(X_val)
    y_pred2 = model2.predict(X_val)
    y_pred3 = model3.predict(X_val)

    # Calculate Mean Squared Error (MSE) for each model
    mse_model1 = mean_squared_error(y_val, y_pred1)
    mse_model2 = mean_squared_error(y_val, y_pred2)
    mse_model3 = mean_squared_error(y_val, y_pred3)

    # Calculate R-squared for each model
    r2_model1 = r2_score(y_val, y_pred1)
    r2_model2 = r2_score(y_val, y_pred2)
    r2_model3 = r2_score(y_val, y_pred3)

    mse_scores_model1.append(mse_model1)
    mse_scores_model2.append(mse_model2)
    mse_scores_model3.append(mse_model3)

    r2_scores_model1.append(r2_model1)
    r2_scores_model2.append(r2_model2)
    r2_scores_model3.append(r2_model3)

# Calculate the average MSE and R-squared across all folds for each model
average_mse_model1 = np.mean(mse_scores_model1)
average_mse_model2 = np.mean(mse_scores_model2)
average_mse_model3 = np.mean(mse_scores_model3)

average_r2_model1 = np.mean(r2_scores_model1)
average_r2_model2 = np.mean(r2_scores_model2)
average_r2_model3 = np.mean(r2_scores_model3)

print(f'Average Mean Squared Error for Model 1: {average_mse_model1}')
print(f'Average R-squared for Model 1: {average_r2_model1}')
print(f'Average Mean Squared Error for Model 2: {average_mse_model2}')
print(f'Average R-squared for Model 2: {average_r2_model2}')
print(f'Average Mean Squared Error for Model 3: {average_mse_model3}')
print(f'Average R-squared for Model 3: {average_r2_model3}')

"""Some Predictions"""

print(model1.predict([[70, 9]]))
print(model2.predict([[70, 9]]))
print(model3.predict([[70, 9]]))

import pickle

filename = 'Random_Forest_Regressor.pkl'
with open('Random_Forest_Regressor.pkl', 'wb') as file:
    pickle.dump(model3, file)

#from google.colab import files